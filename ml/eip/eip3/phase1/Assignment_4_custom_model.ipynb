{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_4_custom_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "_uuid": "f67729355a01c19c62bfa2145d9594b1da821fc6",
        "colab_type": "code",
        "id": "AbFZ1CPnyLEx",
        "outputId": "c871b9fe-c3d3-4d31-b3ca-ab93b4f0b84e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q six numpy scipy matplotlib scikit-image opencv-python imageio\n",
        "!pip install -q keras imgaug\n",
        "!pip install -q tensorboardcolab\n",
        "!pip install -q git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RAOSjgsZyzWs",
        "colab_type": "code",
        "outputId": "f2b9ab31-c95d-450f-9a08-3aaffd2161f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "import os,sys,math\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import Dropout, Flatten, GlobalAveragePooling2D, AveragePooling2D, merge, Activation, Conv2D, MaxPooling2D, Input\n",
        "from keras.layers import BatchNormalization, LeakyReLU, SeparableConv2D, Lambda, Concatenate,Softmax\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, CSVLogger, EarlyStopping"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab_type": "code",
        "id": "jwLq5vZ1yLE_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras_contrib.callbacks import CyclicLR\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "colab_type": "code",
        "id": "beylEPLZyLFm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "22f446b53ec82f3244c33dd780ab24b896178cf9",
        "colab_type": "code",
        "id": "HGIF2j6YyLFc",
        "outputId": "c415452d-fdfd-4800-8d91-0bac772e310f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "cell_type": "code",
      "source": [
        "import google\n",
        "colab_dir='./'\n",
        "weights_dir='./'\n",
        "file_name='EIP_CIFAR_10'\n",
        "if hasattr(google,'colab'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    colab_dir='/content/gdrive/My Drive/Colab Notebooks/'\n",
        "    weights_dir=colab_dir+'weights/'\n",
        "model_file=colab_dir+file_name+'.h5'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tb36NIvdaOu_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_dataset(image_dim=64,augment=True,batch_size=256):\n",
        "  file_exists = os.path.exists(\"tiny-imagenet-200.zip\")\n",
        "  if file_exists:\n",
        "    print(\"Files present. Skipping.\")\n",
        "  else:\n",
        "    print(os.popen('wget http://cs231n.stanford.edu/tiny-imagenet-200.zip').read())\n",
        "    print(os.popen('unzip -qq tiny-imagenet-200.zip').read())\n",
        "    \n",
        "  val_data = pd.read_csv('./tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "  val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)\n",
        "  train_datagen = None\n",
        "  \n",
        "  if augment:\n",
        "    train_datagen = ImageDataGenerator(rescale= 1./255,fill_mode='nearest',\n",
        "      zoom_range = 0.2,horizontal_flip=True,shear_range=0.2,\n",
        "      rotation_range=40,width_shift_range=0.2,height_shift_range=0.2,\n",
        "      featurewise_std_normalization=True)\n",
        "  else:\n",
        "    train_datagen = ImageDataGenerator(rescale= 1./255,featurewise_std_normalization=True)\n",
        "  \n",
        "  valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "  train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(image_dim, image_dim), color_mode='rgb',\n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, interpolation='bicubic')\n",
        "  \n",
        "  validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(image_dim, image_dim),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True,interpolation='bicubic')\n",
        "  #x_batch, y_val_batch = next(train_generator)\n",
        "  #print('Training batch shape:',x_batch.shape)\n",
        "  \n",
        "  return train_generator, validation_generator#, x_batch, y_val_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aa9bb45cb7f0171c15c4b065ade989e82042b15a",
        "colab_type": "code",
        "id": "VKufdLiEyLFy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Augmentation and resizing\n",
        "#augment and then concat samples with original\n",
        "def augment(dataset,flip=0.5,blur=1.0):\n",
        "    ia.seed(1)\n",
        "    seq = iaa.Sequential([iaa.Crop(px=(0, 16)),iaa.Fliplr(0.5),iaa.GaussianBlur(sigma=(0, 3.0))], random_order=True)   \n",
        "    return seq.augment_images(dataset)\n",
        "\n",
        "def augmenter(X,y,start=0,end=1,append=False):\n",
        "    ln=len(X)\n",
        "    print('Before augmentation:',X.shape,y.shape)\n",
        "    start=int(start*ln)\n",
        "    end=int(end*ln)\n",
        "    if append:\n",
        "      new_X=augment(X)[start:end]\n",
        "      new_y=y[start:end]\n",
        "      X=np.concatenate((X,new_X))\n",
        "      y=np.concatenate((y,new_y))\n",
        "    else:\n",
        "      X=augment(X)\n",
        "    print('After augmentation:',X.shape,y.shape)\n",
        "    return (X,y)\n",
        "\n",
        "#26x26 is almost half of 32x32. 22x22 maybe too small even though its exact half.\n",
        "def resize_imgs(imgs,shape=(26,26)):\n",
        "    seq = iaa.Sequential([iaa.Scale({\"height\": shape[0], \"width\": shape[1]})])\n",
        "    return seq.augment_images(imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9d5f083dfa8904a9bd7433e385ad2a0b8a236b22",
        "colab_type": "code",
        "id": "Zw3sldJUyLGg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modval=50\n",
        "max_lr=0.1\n",
        "\n",
        "def cosine_anneal_schedule(t,lr):\n",
        "  global modval,max_lr\n",
        "  modval=int(modval)\n",
        "  cos_inner = (np.pi * (t % modval))/ modval\n",
        "  cos_out = np.cos(cos_inner) + 1\n",
        "  return float(max_lr / 2 * cos_out)\n",
        "\n",
        "def load_prev_model(model_small=None):\n",
        "#     print(os.popen('du -sh '+colab_dir+'*').read())\n",
        "    last_best=os.popen('du -sh '+colab_dir+r'*|sed -r \"s/^[0-9\\.]+[MK]?\\s(.*)$/\\1/g;\"|tail -1').read().strip()\n",
        "    model_prev=None\n",
        "    try:\n",
        "        print('Attempting to load last best model from file - ',end='')\n",
        "        last_best_fn=last_best.split('/')[-1]\n",
        "        last_best_epoch=last_best_fn.split('.')[1].split('-')[0]\n",
        "        model_prev=load_model(last_best)\n",
        "        print('Sucess\\nLoaded '+last_best_fn, 'epoch :', last_best_epoch)\n",
        "    except Exception as e:\n",
        "        print('Failed!\\n',e)\n",
        "        try:\n",
        "            print('Attempting to load last saved model from file - ',end='')\n",
        "            model_prev = load_model(model_file)\n",
        "            print('Sucess\\nLoaded model from file',model_file)\n",
        "        except Exception as e:\n",
        "    #         print(str(e), 'at line ', sys.exc_info()[2].tb_lineno)\n",
        "            print('Failed!\\n',e)\n",
        "            try:\n",
        "                print('Attempting to load in memory, small model - ',end='')\n",
        "                if len(model_small.layers)>1:\n",
        "                    model_prev=model_small\n",
        "                print('Sucess')\n",
        "            except Exception as e:\n",
        "                print('Failed!\\n',e)\n",
        "    return model_prev\n",
        "  \n",
        "def copy_weights(model_to,model_from):\n",
        "    #model_to.set_weights(model_from.get_weights())\n",
        "    s,err=0,0\n",
        "    print('Trying to copy weights')\n",
        "    try:\n",
        "        if len(model_to.layers) >1 and len(model_from.layers) >1:\n",
        "            pass\n",
        "    except Exception as e:\n",
        "        print('Inavlid models',model_to,model_from)\n",
        "        return\n",
        "    for new_layer, layer in zip(model_to.layers[1:], model_from.layers[1:]):\n",
        "        s+=1\n",
        "        try:\n",
        "            new_layer.set_weights(layer.get_weights())\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    print('Done: errors:',err)\n",
        "      \n",
        "#new model with larger i/p layer\n",
        "def larger_model(src_model,shape=(32,32,3)):\n",
        "    new_input=Input(shape)\n",
        "    src_model.layers.pop(0)\n",
        "    new_output=src_model(new_input)\n",
        "    new_model=Model(new_input,new_output)\n",
        "    return new_model\n",
        "\n",
        "# Load CIFAR10 Data\n",
        "def load_data(resize=False,append=False,shape=(26,26),train_augment=True,test_augment=False):\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    \n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "    \n",
        "    if resize:\n",
        "        x_train=resize_imgs(x_train,shape)\n",
        "        x_test=resize_imgs(x_test,shape)\n",
        "    if train_augment:\n",
        "      (x_train, y_train) = augmenter(x_train, y_train,end=1,append=append)\n",
        "    if test_augment:\n",
        "        (x_test, y_test) = augmenter(x_test, y_test,end=1,append=append)\n",
        "    return (x_train, y_train,x_test, y_test)\n",
        "#create a dnn model\n",
        "def create_model(input_shape,num_layers,input_conv_filters=12,input=None):\n",
        "    print('Creating model with input shape',input_shape)\n",
        "    if input is None:\n",
        "        input = Input(input_shape)\n",
        "    First_Conv2D = Conv2D(input_conv_filters, (3,3), use_bias=False ,padding='same')(input)\n",
        "    hidden_dense_blocks = dense_units_chain(n_dense_blocks,First_Conv2D,num_filter,dropout_rate,num_layers)\n",
        "    Last_Block = add_denseblock(hidden_dense_blocks, num_filter, dropout_rate)\n",
        "    output = output_layer(Last_Block)\n",
        "    model = Model(inputs=[input], outputs=[output])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "b5QrXF2BznZs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sc=False\n",
        "after_transistion = True\n",
        "# Dense Block\n",
        "def add_denseblock(input,num_layers, growth_rate = 12, dropout_rate = 0.2, bn_layers=48, middle_layers=24):\n",
        "    \n",
        "    temp = input\n",
        "    \n",
        "    #if len(Block_outputs)>1:\n",
        "    #  bv = Block_outputs[-2]\n",
        "    #  #temp = Concatenate(axis=-1)([Block_outputs[-2],[temp]])\n",
        "    #  print(bv)\n",
        "    \n",
        "    for _ in range(num_layers):\n",
        "        ######################################################################################################################################\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)        \n",
        "        Conv2D_1_1_bottleneck = Conv2D(bn_layers, (1,1), use_bias=False ,padding='same',kernel_initializer='he_normal')(relu) #bottleneck  <===\n",
        "        ###################################################################################################################################### |\n",
        "        #BatchNorm = BatchNormalization()(Conv2D_1_1_bottleneck)\n",
        "        #relu = Activation('relu')(BatchNorm)        \n",
        "        #Conv2D_1_1_bottleneck = Conv2D(bn_layers, (3,3), use_bias=False ,padding='same',kernel_initializer='he_normal')(relu) #bottleneck  <===\n",
        "        ###################################################################################################################################### |\n",
        "        #BatchNorm = BatchNormalization()(Conv2D_1_1_bottleneck) #extra layer                                                                 # |\n",
        "        #relu = Activation('relu')(BatchNorm) #extra layer                                                                                    # |\n",
        "        #Conv2D_1_1 = Conv2D(middle_layers, (1,1), use_bias=False ,padding='same',kernel_initializer='he_normal')(relu) #extra layer          # |\n",
        "        ###################################################################################################################################### |\n",
        "        BatchNorm = BatchNormalization()(Conv2D_1_1_bottleneck) #bottleneck   <================================================================\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(growth_rate, (3,3), use_bias=False ,padding='same',kernel_initializer='he_normal')(relu)\n",
        "        ######################################################################################################################################|\n",
        "        \n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "    #if not after_transistion:\n",
        "    #  Block_outputs.append(temp)\n",
        "    return temp\n",
        "\n",
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2),padding='same')(Conv2D_BottleNeck)\n",
        "    #if after_transistion:\n",
        "    #  Block_outputs.append(avg)\n",
        "    return avg\n",
        "\n",
        "  \n",
        "def output_layer(input,num_classes,mf=2,nl=2):\n",
        "    inp = input\n",
        "    for i in range(nl,-1,-1):\n",
        "      classes = int(num_classes*(mf**i))\n",
        "      BatchNorm = BatchNormalization()(inp)\n",
        "      relu = Activation('relu')(BatchNorm)\n",
        "      conv1_1 = Conv2D(classes,(1,1),use_bias=False,kernel_initializer='he_normal',padding='same')(relu)\n",
        "      conv3_3 = Conv2D(classes,(3,3),use_bias=False,kernel_initializer='he_normal',padding='same')(conv1_1)\n",
        "      inp = conv3_3\n",
        "    \n",
        "    GlobalAveragePooling = GlobalAveragePooling2D(data_format='channels_last')(inp)\n",
        "    sf = Softmax()(GlobalAveragePooling)\n",
        "    return sf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ylypmrZzhxBN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def custom_model(input_shape,initial_layers,num_layers,db_arch,dropout_rate=0,trans_2k=False,n_blocks=3,omf=2,onl=2):\n",
        "  Block,Transition = None,None\n",
        "  bn_layers,middle_layers,growth_rate = db_arch\n",
        "  \n",
        "  input = Input(shape=input_shape)\n",
        "  First_Conv2D = Conv2D(initial_layers, (3,3), use_bias=False ,padding='same')(input)\n",
        "  num_filter=initial_layers\n",
        "  \n",
        "  input_layer = First_Conv2D\n",
        "  for i in range(n_blocks):\n",
        "    Block = add_denseblock(input_layer,num_layers, growth_rate, dropout_rate,bn_layers,middle_layers)\n",
        "    \n",
        "    num_filter+=growth_rate*num_layers\n",
        "    num_filter=(growth_rate*2) if trans_2k else num_filter//2    \n",
        "    \n",
        "    Transition = add_transition(Block, num_filter, dropout_rate)    \n",
        "    input_layer = Transition\n",
        "  \n",
        "  #Last_Block = add_denseblock(Transition, num_layers, growth_rate, dropout_rate,bn_layers,middle_layers)\n",
        "  output = output_layer(Block,num_classes,omf,onl)\n",
        "  model = Model(inputs=[input], outputs=[output])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "991f8e371577a1f2e8197827dab5aac2406ef1b1",
        "colab_type": "code",
        "id": "kpe9EljYyLGq",
        "outputId": "51802178-3802-4900-998a-9561c8c374df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "print('====================HYPER PARAMETERS====================')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================HYPER PARAMETERS====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SizS-NnKfkQf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_filter = 0 # add it up as you go\n",
        "compression = 0.5\n",
        "dropout_rate =0#0.2#.5\n",
        "num_classes = 200\n",
        "train_ds_size=100000\n",
        "validation_ds_size=10000\n",
        "\n",
        "modval=20\n",
        "max_lr=0.3\n",
        "image_dim = 32\n",
        "batch_size = 64\n",
        "inp_shape = (image_dim,image_dim,3)\n",
        "\n",
        "n_blocks=3\n",
        "num_layers=10#26\n",
        "initial_layers=24\n",
        "db_archs=[[128,64,32],[96,48,24],[48,24,12]]\n",
        "dbi = 1\n",
        "db_arch=db_archs[dbi]\n",
        "\n",
        "hist=[]\n",
        "epochs=initial_epoch=0\n",
        "Block_outputs = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oUMIv4edk9ei",
        "colab_type": "code",
        "outputId": "e2b03a91-379e-432d-8fb6-da86c165942f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "cell_type": "code",
      "source": [
        "model = custom_model(inp_shape,initial_layers,num_layers,db_arch,n_blocks=n_blocks,trans_2k=False,omf=2,onl=0)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "S0I-BnZt6mCg",
        "outputId": "bf6ff188-57da-4206-aefe-4b14fd22218c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "tbc=TensorBoardColabCallback(TensorBoardColab())\n",
        "hist=[]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://55ec2c29.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nnCBJrCs11vl",
        "outputId": "9572bab0-4b53-4d49-cc0b-ef956ab5ae69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9308
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True))\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 24)   648         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 24)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 24)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 96)   2304        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 96)   384         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 96)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 24)   20736       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 48)   0           conv2d_1[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 48)   192         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 48)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 96)   4608        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 96)   384         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 96)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 24)   20736       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 72)   0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 72)   288         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 72)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 96)   6912        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 96)   384         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 96)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 24)   20736       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 96)   0           concatenate_2[0][0]              \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 96)   384         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 96)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 96)   9216        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 96)   384         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 96)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 24)   20736       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 120)  0           concatenate_3[0][0]              \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 120)  480         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 120)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 96)   11520       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 96)   384         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 24)   20736       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 144)  0           concatenate_4[0][0]              \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 144)  576         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 144)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 96)   13824       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 96)   384         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 96)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 24)   20736       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 168)  0           concatenate_5[0][0]              \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 168)  672         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 168)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 96)   16128       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 96)   384         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 96)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 24)   20736       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 192)  0           concatenate_6[0][0]              \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 192)  768         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 192)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 96)   18432       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 96)   384         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 24)   20736       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 216)  0           concatenate_7[0][0]              \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 216)  864         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 216)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 96)   20736       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 96)   384         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 96)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 24)   20736       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 240)  0           concatenate_8[0][0]              \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 240)  960         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 240)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 96)   23040       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 96)   384         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 96)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 24)   20736       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 264)  0           concatenate_9[0][0]              \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 264)  1056        concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 264)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 132)  34848       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 132)  0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 132)  528         average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 132)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   12672       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   384         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 24)   20736       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 16, 16, 156)  0           average_pooling2d_1[0][0]        \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 156)  624         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 156)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 96)   14976       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 96)   384         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 96)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 24)   20736       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 16, 16, 180)  0           concatenate_11[0][0]             \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 16, 16, 180)  720         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 180)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 96)   17280       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 96)   384         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 96)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 24)   20736       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 16, 16, 204)  0           concatenate_12[0][0]             \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 204)  816         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 204)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 16, 16, 96)   19584       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 16, 16, 96)   384         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 16, 16, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 16, 16, 24)   20736       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 16, 16, 228)  0           concatenate_13[0][0]             \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 16, 16, 228)  912         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 16, 16, 228)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 16, 16, 96)   21888       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 16, 16, 96)   384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 16, 16, 96)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 16, 16, 24)   20736       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 16, 16, 252)  0           concatenate_14[0][0]             \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 16, 16, 252)  1008        concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 16, 16, 252)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 16, 16, 96)   24192       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 16, 16, 96)   384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 16, 16, 96)   0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 24)   20736       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 276)  0           concatenate_15[0][0]             \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 16, 16, 276)  1104        concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 16, 16, 276)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 16, 16, 96)   26496       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 16, 16, 96)   384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 16, 16, 96)   0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 16, 16, 24)   20736       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 300)  0           concatenate_16[0][0]             \n",
            "                                                                 conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 16, 16, 300)  1200        concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 16, 16, 300)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 16, 16, 96)   28800       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 16, 16, 96)   384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 16, 16, 96)   0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 16, 16, 24)   20736       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 324)  0           concatenate_17[0][0]             \n",
            "                                                                 conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 16, 16, 324)  1296        concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 16, 16, 324)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 16, 16, 96)   31104       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 16, 16, 96)   384         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 16, 16, 96)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 16, 16, 24)   20736       activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 348)  0           concatenate_18[0][0]             \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 16, 16, 348)  1392        concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 16, 16, 348)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 16, 16, 96)   33408       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 16, 16, 96)   384         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 16, 16, 96)   0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 16, 16, 24)   20736       activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 372)  0           concatenate_19[0][0]             \n",
            "                                                                 conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 16, 16, 372)  1488        concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 16, 16, 372)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 16, 16, 186)  69192       activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 8, 8, 186)    0           conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 8, 8, 186)    744         average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 8, 8, 186)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 8, 8, 96)     17856       activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 8, 8, 96)     384         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 8, 8, 96)     0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 8, 8, 24)     20736       activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 8, 8, 210)    0           average_pooling2d_2[0][0]        \n",
            "                                                                 conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 8, 8, 210)    840         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 8, 8, 210)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 8, 8, 96)     20160       activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 8, 8, 96)     384         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 8, 8, 96)     0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 8, 8, 24)     20736       activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 8, 8, 234)    0           concatenate_21[0][0]             \n",
            "                                                                 conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 8, 8, 234)    936         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 8, 8, 234)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 8, 8, 96)     22464       activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 8, 8, 96)     384         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 8, 8, 96)     0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 8, 8, 24)     20736       activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 8, 8, 258)    0           concatenate_22[0][0]             \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 8, 8, 258)    1032        concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 8, 8, 258)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 8, 8, 96)     24768       activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 8, 8, 96)     384         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 8, 8, 96)     0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 8, 8, 24)     20736       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 8, 8, 282)    0           concatenate_23[0][0]             \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 8, 8, 282)    1128        concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 8, 8, 282)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 8, 8, 96)     27072       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 8, 8, 96)     384         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 8, 8, 96)     0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 8, 8, 24)     20736       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 8, 8, 306)    0           concatenate_24[0][0]             \n",
            "                                                                 conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 8, 8, 306)    1224        concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 8, 8, 306)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 8, 8, 96)     29376       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 8, 8, 96)     384         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 8, 8, 96)     0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 8, 8, 24)     20736       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 8, 8, 330)    0           concatenate_25[0][0]             \n",
            "                                                                 conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 8, 8, 330)    1320        concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 8, 8, 330)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 8, 8, 96)     31680       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 8, 8, 96)     384         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 8, 8, 96)     0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 8, 8, 24)     20736       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 8, 8, 354)    0           concatenate_26[0][0]             \n",
            "                                                                 conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 8, 8, 354)    1416        concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 8, 8, 354)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 8, 8, 96)     33984       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 8, 8, 96)     384         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 8, 8, 96)     0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 8, 8, 24)     20736       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 8, 8, 378)    0           concatenate_27[0][0]             \n",
            "                                                                 conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 8, 8, 378)    1512        concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 8, 8, 378)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 8, 8, 96)     36288       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 8, 8, 96)     384         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 8, 8, 96)     0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 8, 8, 24)     20736       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 8, 8, 402)    0           concatenate_28[0][0]             \n",
            "                                                                 conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 8, 8, 402)    1608        concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 8, 8, 402)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 8, 8, 96)     38592       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 8, 8, 96)     384         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 8, 8, 96)     0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 8, 8, 24)     20736       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 8, 8, 426)    0           concatenate_29[0][0]             \n",
            "                                                                 conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 8, 8, 426)    1704        concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 8, 8, 426)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 8, 8, 200)    85200       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 8, 8, 200)    360000      conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 200)          0           conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "softmax_1 (Softmax)             (None, 200)          0           global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 1,853,736\n",
            "Trainable params: 1,832,532\n",
            "Non-trainable params: 21,204\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EAsg9mA3ZLSY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from keras.datasets import cifar10\n",
        "# x_train, y_train, x_test, y_test = load_data(resize=False,append=False,shape=(image_dim,image_dim))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "A89juSamtr--",
        "outputId": "83aaf7ee-f78e-4de7-f196-9a1bfa330354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "cell_type": "code",
      "source": [
        "#callbacks\n",
        "batch_size=64#128\n",
        "modval=8\n",
        "max_lr=0.3\n",
        "augment_data = False\n",
        "train_generator, validation_generator = create_dataset(image_dim=image_dim,augment=augment_data,batch_size=batch_size)\n",
        "\n",
        "\n",
        "model_checkpointer=ModelCheckpoint(weights_dir+'large_weights.{epoch:02d}-{val_acc:.2f}.h5', monitor='val_loss',verbose=1, save_best_only=True, save_weights_only=False, mode='min', period=5)\n",
        "clr = CyclicLR(base_lr=0.1, max_lr=0.2,step_size=8*(int(train_ds_size/batch_size)))\n",
        "els = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10, verbose=1, mode='auto', baseline=None, restore_best_weights=False)\n",
        "\n",
        "use_cosine_annealing=False\n",
        "lrs = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.001)\n",
        "lrs=LearningRateScheduler(cosine_anneal_schedule) if use_cosine_annealing else clr\n",
        "callbacks = [model_checkpointer,lrs,els,tbc]\n",
        "initial_epoch=epochs\n",
        "epochs=10\n",
        "epochs+=initial_epoch\n",
        "\n",
        "#h=model.fit(x_train, y_train, batch_size=batch_size, verbose=1,initial_epoch=initial_epoch,epochs=epochs, callbacks=callbacks, validation_data=(x_test,y_test))\n",
        "h =model.fit_generator(train_generator,steps_per_epoch=int(train_ds_size/batch_size),verbose=1,epochs=epochs,callbacks=callbacks,validation_data=validation_generator,validation_steps=int(validation_ds_size/batch_size))\n",
        "hist.append(h)\n",
        "model.save(model_file)\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:346: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:699: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:707: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  57/1562 [>.............................] - ETA: 16:59 - loss: 5.7619 - acc: 0.0074"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vBF-88UvnzRt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#callbacks\n",
        "batch_size=64#128\n",
        "modval=8\n",
        "max_lr=0.3\n",
        "augment_data = True\n",
        "train_generator, validation_generator = create_dataset(image_dim=image_dim,augment=augment_data,batch_size=batch_size)\n",
        "\n",
        "\n",
        "model_checkpointer=ModelCheckpoint(weights_dir+'large_weights.{epoch:02d}-{val_acc:.2f}.h5', monitor='val_loss',verbose=1, save_best_only=True, save_weights_only=False, mode='min', period=5)\n",
        "clr = CyclicLR(base_lr=0.1, max_lr=0.2,step_size=8*(int(train_ds_size/batch_size)))\n",
        "els = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10, verbose=1, mode='auto', baseline=None, restore_best_weights=False)\n",
        "\n",
        "use_cosine_annealing=False\n",
        "lrs = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.001)\n",
        "lrs=LearningRateScheduler(cosine_anneal_schedule) if use_cosine_annealing else clr\n",
        "callbacks = [model_checkpointer,lrs,els,tbc]\n",
        "initial_epoch=epochs\n",
        "epochs=20#24\n",
        "epochs+=initial_epoch\n",
        "\n",
        "#h=model.fit(x_train, y_train, batch_size=batch_size, verbose=1,initial_epoch=initial_epoch,epochs=epochs, callbacks=callbacks, validation_data=(x_test,y_test))\n",
        "h =model.fit_generator(train_generator,steps_per_epoch=int(train_ds_size/batch_size),verbose=1,epochs=epochs,callbacks=callbacks,validation_data=validation_generator,validation_steps=int(validation_ds_size/batch_size))\n",
        "hist.append(h)\n",
        "model.save(model_file)\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6151d97fb488aed1553bb9ae29fcb9e3e0bf1f08",
        "colab_type": "code",
        "id": "kEa47QYDyLJ9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('====================END OF LARGER MODEL====================')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}